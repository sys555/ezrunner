# EZ Runner

> **Run any LLM, anywhere, offline.**
> ä¸€æ¡å‘½ä»¤ï¼Œå°†ä»»æ„å¤§è¯­è¨€æ¨¡å‹æ‰“åŒ…ä¸ºç¦»çº¿å¯è¿è¡Œçš„ Docker é•œåƒã€‚

[![License: Apache-2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![Python 3.11+](https://img.shields.io/badge/python-3.11%2B-blue.svg)](https://www.python.org/downloads/)

---

## ğŸ¯ æ ¸å¿ƒç†å¿µ

**é—®é¢˜ï¼š** å¦‚ä½•åœ¨ç¦»çº¿ç¯å¢ƒè¿è¡Œæœ€æ–°çš„ LLMï¼Ÿ

**ç­”æ¡ˆï¼š** EZ Runner - åœ¨çº¿æœºå™¨æ‰“åŒ…ï¼Œç¦»çº¿æœºå™¨è¿è¡Œ

```bash
# åœ¨çº¿æœºå™¨
ezrunner pack qwen/Qwen-3-4B-Guard -o model.tar

# ä¼ è¾“åˆ°ç¦»çº¿æœºå™¨
scp model.tar offline-server:/data/

# ç¦»çº¿æœºå™¨è¿è¡Œ
ezrunner run model.tar
# âœ… API: http://localhost:8080
```

---

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸš€ æ”¯æŒä»»æ„æ¨¡å‹

```bash
# æ”¯æŒ HuggingFace æ‰€æœ‰æ¨¡å‹
ezrunner pack meta-llama/Llama-3.2-1B-Instruct

# æ”¯æŒ ModelScope æ‰€æœ‰æ¨¡å‹
ezrunner pack qwen/Qwen2.5-7B-Instruct

# åˆšå‘å¸ƒçš„æ–°æ¨¡å‹ï¼Ÿç«‹å³å¯ç”¨
ezrunner pack deepseek/DeepSeek-R1  # å‘å¸ƒ 1 åˆ†é’Ÿåå³å¯æ‰“åŒ…
```

### ğŸ“¦ è‡ªåŒ…å«é•œåƒ

```
Docker é•œåƒåŒ…å«:
â”œâ”€â”€ PyTorch + CUDA        (æ¨ç†å¼•æ“)
â”œâ”€â”€ æ¨¡å‹æƒé‡              (safetensors)
â”œâ”€â”€ OpenAI å…¼å®¹ API       (å³æ’å³ç”¨)
â””â”€â”€ æ‰€æœ‰ä¾èµ–              (é›¶é…ç½®)
```

### ğŸ›ï¸ ç¡¬ä»¶è‡ªé€‚åº”

```bash
# è‡ªåŠ¨æ£€æµ‹ç›®æ ‡ç¡¬ä»¶
ezrunner pack qwen/Qwen-7B --target-gpu 8   # 8GB æ˜¾å­˜

# è¾“å‡ºï¼š
# âœ… æ£€æµ‹åˆ°æ˜¾å­˜å……è¶³ï¼Œä½¿ç”¨ vLLM (é«˜æ€§èƒ½)
# âœ… é•œåƒå¤§å°: 15.2 GB
```

### ğŸ”Œ OpenAI å…¼å®¹ API

```python
from openai import OpenAI

client = OpenAI(
    api_key="dummy",
    base_url="http://localhost:8080/v1"
)

response = client.chat.completions.create(
    model="qwen",
    messages=[{"role": "user", "content": "ä½ å¥½"}]
)
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
pip install ezrunner
```

### 5 åˆ†é’Ÿä¸Šæ‰‹

#### **æ­¥éª¤ 1: åœ¨çº¿æœºå™¨æ‰“åŒ…**

```bash
# æ‰“åŒ…æ¨¡å‹
ezrunner pack qwen/Qwen-3-4B-Guard -o qwen3.tar

# è¾“å‡º:
# [1/4] å‘ç°æ¨¡å‹: qwen/Qwen-3-4B-Guard
#   â†’ æ ¼å¼: safetensors, å¤§å°: 4.2 GB
# [2/4] é€‰æ‹©å¼•æ“: PyTorch (Transformers)
# [3/4] æ„å»º Docker é•œåƒ
#   â†’ ä¸‹è½½æ¨¡å‹...
#   â†’ å®‰è£…ä¾èµ–...
# [4/4] å¯¼å‡ºé•œåƒ: qwen3.tar (12.5 GB)
# âœ… å®Œæˆï¼
```

#### **æ­¥éª¤ 2: ä¼ è¾“åˆ°ç¦»çº¿æœºå™¨**

```bash
# Uç›˜ã€å†…ç½‘ä¼ è¾“ã€ç­‰
scp qwen3.tar offline-server:/data/
```

#### **æ­¥éª¤ 3: ç¦»çº¿æœºå™¨è¿è¡Œ**

```bash
# åŠ è½½å¹¶è¿è¡Œ
ezrunner run qwen3.tar

# æˆ–æ‰‹åŠ¨
docker load < qwen3.tar
docker run -d --gpus all -p 8080:8080 ezrunner-qwen-3-4b-guard
```

#### **æ­¥éª¤ 4: æµ‹è¯•**

```bash
curl http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen",
    "messages": [{"role": "user", "content": "ä½ å¥½"}]
  }'
```

---

## ğŸ“– ä½¿ç”¨æŒ‡å—

### åŸºæœ¬ç”¨æ³•

```bash
# æ‰“åŒ…æ¨¡å‹
ezrunner pack <model_id> [OPTIONS]

# é€‰é¡¹:
  -o, --output PATH          è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: model.tar)
  --engine [auto|transformers|vllm]
                             æ¨ç†å¼•æ“ (é»˜è®¤: auto)
  --target-gpu INT           ç›®æ ‡æœºå™¨æ˜¾å­˜ (GB)
  --port INT                 API ç«¯å£ (é»˜è®¤: 8080)
  --quantization [4bit|8bit] é‡åŒ–çº§åˆ« (å¯é€‰)
```

### é«˜çº§ç”¨æ³•

#### **1. æŒ‡å®šæ¨ç†å¼•æ“**

```bash
# è‡ªåŠ¨é€‰æ‹© (æ¨è)
ezrunner pack qwen/Qwen-7B --engine auto

# å¼ºåˆ¶ä½¿ç”¨ Transformers (å…¼å®¹æ€§æœ€å¥½)
ezrunner pack qwen/Qwen-7B --engine transformers

# å¼ºåˆ¶ä½¿ç”¨ vLLM (é«˜æ€§èƒ½ï¼Œéœ€è¦å……è¶³æ˜¾å­˜)
ezrunner pack qwen/Qwen-7B --engine vllm
```

#### **2. é‡åŒ–æ”¯æŒ**

```bash
# 4-bit é‡åŒ– (èŠ‚çœæ˜¾å­˜ 75%)
ezrunner pack qwen/Qwen-7B --quantization 4bit

# 8-bit é‡åŒ– (èŠ‚çœæ˜¾å­˜ 50%)
ezrunner pack qwen/Qwen-7B --quantization 8bit
```

#### **3. å¤š GPU æ”¯æŒ**

```bash
# æŒ‡å®šç›®æ ‡æœ‰ 2 å¼  GPU
ezrunner pack qwen/Qwen-72B \
  --target-gpu 40 \
  --target-gpu-count 2
```

#### **4. è‡ªå®šä¹‰ç«¯å£**

```bash
ezrunner pack qwen/Qwen-7B --port 8888
```

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

è¯¦è§ [ARCHITECTURE.md](ARCHITECTURE.md)

### æ ¸å¿ƒæµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  åœ¨çº¿æœºå™¨: ezrunner pack                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. æ¨¡å‹å‘ç° (ModelScope/HuggingFace API)   â”‚
â”‚  2. ç¡¬ä»¶åˆ†æ (é€‰æ‹©æœ€ä¼˜å¼•æ“)                  â”‚
â”‚  3. ç”Ÿæˆ Dockerfile                          â”‚
â”‚  4. docker build (ä¸‹è½½æ¨¡å‹åˆ°é•œåƒå†…)          â”‚
â”‚  5. docker save > model.tar                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“ (Uç›˜/å†…ç½‘ä¼ è¾“)
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç¦»çº¿æœºå™¨: ezrunner run                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. docker load < model.tar                  â”‚
â”‚  2. docker run --gpus all -p 8080:8080       â”‚
â”‚  3. è®¿é—® http://localhost:8080               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š æ–‡æ¡£

- [æ¶æ„è®¾è®¡](ARCHITECTURE.md)
- [API æ–‡æ¡£](API.md)
- [è´¡çŒ®æŒ‡å—](CONTRIBUTING.md)

---

## ğŸ“Š ä¸å…¶ä»–æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | æ¨¡å‹è¦†ç›– | ç¦»çº¿æ”¯æŒ | æ˜“ç”¨æ€§ | æ€§èƒ½ |
|------|---------|---------|--------|------|
| **EZ Runner** | âœ… æ‰€æœ‰æ¨¡å‹ | âœ… å®Œå…¨ç¦»çº¿ | â­â­â­â­â­ | â­â­â­â­ |
| **Ollama** | âš ï¸ éœ€è¦ GGUF | âœ… ç¦»çº¿ | â­â­â­â­â­ | â­â­â­ |
| **OpenLLM** | âš ï¸ é¢„å®šä¹‰åˆ—è¡¨ | âš ï¸ è¿è¡Œæ—¶ä¸‹è½½ | â­â­â­â­ | â­â­â­â­ |
| **Xinference** | âš ï¸ é¢„å®šä¹‰åˆ—è¡¨ | âš ï¸ è¿è¡Œæ—¶ä¸‹è½½ | â­â­â­â­ | â­â­â­â­ |
| **vLLM** | âœ… æ‰€æœ‰æ¨¡å‹ | âŒ éœ€è¦åœ¨çº¿ | â­â­â­ | â­â­â­â­â­ |

---

## ğŸ™ è‡´è°¢

- **PyTorch** - å¼ºå¤§çš„æ·±åº¦å­¦ä¹ æ¡†æ¶
- **HuggingFace Transformers** - ç»Ÿä¸€çš„æ¨¡å‹æ¥å£
- **vLLM** - é«˜æ€§èƒ½æ¨ç†å¼•æ“
- **ModelScope** - å›½å†…æ¨¡å‹ç”Ÿæ€æ”¯æŒ

---

**EZ Runner - Run any LLM, anywhere, offline. ğŸš€**
